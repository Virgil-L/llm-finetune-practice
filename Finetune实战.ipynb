{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM82bj0tWotlY5LIAm8exx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 准备工作"
      ],
      "metadata": {
        "id": "gn7Gqij9DBnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 环境准备\n"
      ],
      "metadata": {
        "id": "oVFoZq4c4gqo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8RMz9YVAVoX"
      },
      "outputs": [],
      "source": [
        "#关闭安装的输出\n",
        "%%capture \n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install torchinfo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 函数库与gpu使用"
      ],
      "metadata": {
        "id": "zojDZMAt1_db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "from datasets import load_from_disk\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import load_metric\n",
        "from transformers.trainer_utils import EvalPrediction\n",
        "import evaluate\n",
        "\n",
        "# 使用gpu进行训练\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "# gpu型号\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "wan-g7-A3S_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4c720d-d0fe-4b5c-d6ce-b0d6a27afa44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Tue Mar 14 08:46:50 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0    32W /  70W |   6147MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 goole drive连接"
      ],
      "metadata": {
        "id": "YqWgeHxxDQb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aexU2WFDAc_",
        "outputId": "25e627ac-8df8-40fe-faa2-922637c93ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 数据预处理"
      ],
      "metadata": {
        "id": "L8yj_QwJ4vdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 数据集导入"
      ],
      "metadata": {
        "id": "iAue3vw-DwXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, split, filepath):\n",
        "    self.dataset = load_dataset(path=filepath,split=split)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "  \n",
        "  def __getitem__(self, i):\n",
        "    text = self.dataset[i]['text']\n",
        "    label = self.dataset[i]['label']\n",
        "\n",
        "    return text, label\n",
        "\n",
        "\n",
        "train_data = Dataset(filepath = 'seamew/ChnSentiCorp',split = 'train')\n",
        "val_data = Dataset(filepath = 'seamew/ChnSentiCorp',split = 'validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sb_AGGZ1Iiy",
        "outputId": "749bf79f-1a48-4fc6-cc27-ff9a563ae0fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset chn_senti_corp (/root/.cache/huggingface/datasets/seamew___chn_senti_corp/default/0.0.0/1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85)\n",
            "WARNING:datasets.builder:Found cached dataset chn_senti_corp (/root/.cache/huggingface/datasets/seamew___chn_senti_corp/default/0.0.0/1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 分词和编码"
      ],
      "metadata": {
        "id": "7pVUZsVQDVBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mengzi_token = BertTokenizer.from_pretrained(\"Langboat/mengzi-bert-base-fin\")\n",
        "\n",
        "bert_bc_token = BertTokenizer.from_pretrained(\n",
        "    pretrained_model_name_or_path='bert-base-chinese',\n",
        "    cache_dir=None,\n",
        "    force_download=False\n",
        ")\n",
        "\n",
        "#获取字典\n",
        "#token_dict = tokenizer.get_vocab()\n",
        "#type(token_dict), len(token_dict), '月光' in token_dict\n",
        "#添加新词\n",
        "#tokenizer.add_token(new_tokens=['月光','希望'])\n",
        "#添加新符号\n",
        "#tokenizer.add_special_tokens({'eos_token':'[EOS]'})"
      ],
      "metadata": {
        "id": "rJpCYEQJAxX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 定义批处理函数"
      ],
      "metadata": {
        "id": "IvSQLaDQ5nWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bc_collate_fn(data):\n",
        "  sents = [i[0] for i in data]\n",
        "  labels = [i[1] for i in data]\n",
        "  #编码\n",
        "  data = bert_bc_token.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
        "                                 truncation=True,\n",
        "                                 padding='max_length',\n",
        "                                 max_length=512,\n",
        "                                 return_tensors='pt',\n",
        "                                 return_length=True)\n",
        "  #input_ids:编码之后的数字\n",
        "  #attention_mask:补零的位置三0，其他位置是1\n",
        "  input_ids = data['input_ids'].to(device)\n",
        "  attention_mask = data['attention_mask'].to(device)\n",
        "  token_type_ids = data['token_type_ids'].to(device)\n",
        "  labels = torch.Tensor(labels).to(device)\n",
        "\n",
        "  return input_ids, attention_mask, token_type_ids, labels\n",
        "\n",
        "\n",
        "def mengzi_collate_fn(data):\n",
        "  sents = [i[0] for i in data]\n",
        "  labels = [i[1] for i in data]\n",
        "  #编码\n",
        "  data = mengzi_token.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
        "                                 truncation=True,\n",
        "                                 padding='max_length',\n",
        "                                 max_length=512,\n",
        "                                 return_tensors='pt',\n",
        "                                 return_length=True)\n",
        "  \n",
        "  #input_ids:编码之后的数字\n",
        "  #attention_mask:补零的位置三0，其他位置是1\n",
        "  input_ids = data['input_ids'].to(device)\n",
        "  attention_mask = data['attention_mask'].to(device)\n",
        "  token_type_ids = data['token_type_ids'].to(device)\n",
        "  labels = torch.Tensor(labels).to(device)\n",
        "\n",
        "  return input_ids, attention_mask, token_type_ids, labels\n",
        "\n",
        "#导入数据，这一步合并到trainner中了\n",
        "bc_loader = DataLoader(dataset=train_data,\n",
        "                    batch_size=64,\n",
        "                    collate_fn=bc_collate_fn,\n",
        "                    shuffle=True,\n",
        "                    drop_last=True)\n",
        "\n",
        "mengzi_loader = DataLoader(dataset=train_data,\n",
        "                    batch_size=64,\n",
        "                    collate_fn=mengzi_collate_fn,\n",
        "                    shuffle=True,\n",
        "                    drop_last=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=val_data,\n",
        "                           batch_size=64,\n",
        "                           collate_fn=mengzi_collate_fn,\n",
        "                           shuffle=True,\n",
        "                           drop_last=True)\n",
        "\n",
        "# for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(mengzi_loader):\n",
        "#   break\n",
        "# print(len(mengzi_loader))\n",
        "# input_ids.shape, attention_mask.shape, token_type_ids.shape, labels.shape"
      ],
      "metadata": {
        "id": "BG0IpD_J5qW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 模型\n"
      ],
      "metadata": {
        "id": "Djt3oN503eH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 加载预训练模型"
      ],
      "metadata": {
        "id": "w18MfAc9EZ6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#加载预训练模型\n",
        "bert_bc_pretrained = BertModel.from_pretrained(\"bert-base-chinese\").to(device)\n",
        "mengzi_pretrained = BertModel.from_pretrained(\"Langboat/mengzi-bert-base-fin\").to(device)\n",
        "\n",
        "#不使用finetuning，直接冻结预训练模型的参数\n",
        "for param in bert_bc_pretrained.parameters():\n",
        "  param.requires_grad_(False)\n",
        "\n",
        "#模型试算\n",
        "#out = bert_bc_pretrained(input_ids=input_ids,\n",
        "#                 attention_mask=attention_mask,\n",
        "#                 token_type_ids=token_type_ids)\n",
        "\n",
        "#out.last_hidden_state.shape\n",
        "\n",
        "print('param_num: ' + str(sum([i.nelement() for i in mengzi_pretrained.parameters()]) / 10000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FS9Y1woEXRK",
        "outputId": "190c3576-8fa7-4e1f-a2a9-2a8b9ef2a516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at Langboat/mengzi-bert-base-fin were not used when initializing BertModel: ['cls.predictions.bias', 'sop.cls.weight', 'cls.predictions.decoder.weight', 'pos_head.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'pos_transform.dense.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'pos_transform.dense.bias', 'cls.predictions.transform.dense.bias', 'sop.cls.bias', 'pos_transform.LayerNorm.weight', 'pos_transform.LayerNorm.bias', 'pos_head.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "param_num: 10226.7648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 定义下游任务模型"
      ],
      "metadata": {
        "id": "LkNE7SM1xg2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = nn.Linear(768,2)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "    with torch.no_grad():\n",
        "      out = bert_bc_pretrained(input_ids=input_ids,\n",
        "                 attention_mask=attention_mask,\n",
        "                 token_type_ids=token_type_ids)\n",
        "      \n",
        "    out = self.fc(out.last_hidden_state[:, 0])\n",
        "\n",
        "    out = out.softmax(dim=1)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = Model().to(device)"
      ],
      "metadata": {
        "id": "rox3vdQmxj1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 训练下游任务模型"
      ],
      "metadata": {
        "id": "dztSnKfh0K43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #定义优化器、损失函数、评价指标\n",
        "# optimizer = AdamW(model.parameters(), lr=5e-4)\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "# metric = load_metric('accuracy')\n",
        "\n",
        "# #初始化训练参数\n",
        "# args = TrainingArguments(output_dir='./output_dir',\n",
        "#                          overwrite_output_dir = False,\n",
        "#                          evaluation_strategy='epoch',\n",
        "#                          num_train_epochs = 10,\n",
        "#                          learning_rate = 1e-4, #优化器默认为AdamW\n",
        "#                          adam_beta1 = 0.9,\n",
        "#                          adam_beta2 = 0.999,\n",
        "#                          adam_epsilon = 1e-8,\n",
        "#                          weight_decay = 1e-2, #各层的权重衰减\n",
        "#                          max_grad_norm = 1.0, #梯度裁剪\n",
        "#                          per_device_eval_batch_size = 64,\n",
        "#                          per_device_train_batch_size = 64,\n",
        "#                          lr_scheduler_type = 'linear',\n",
        "#                          save_strategy = 'epoch',\n",
        "#                          no_cuda = False,\n",
        "#                          seed = 1024,\n",
        "#                          data_seed = 1024,\n",
        "#                          load_best_model_at_end = False,\n",
        "#                          metric_for_best_model = 'loss',\n",
        "#                          greater_is_better = False\n",
        "#                          )\n",
        "\n",
        "# #初始化训练器                         \n",
        "# trainer = Trainer(\n",
        "#     model = model,\n",
        "#     args = args,\n",
        "#     data_collator = mengzi_collate_fn, #构建batch\n",
        "#     train_dataset = train_data,\n",
        "#     eval_dataset = val_data,\n",
        "#     compute_metrics = metric,\n",
        "#     tokenizer = mengzi_token\n",
        "#     #callbacks = \n",
        "#     #optimizers = \n",
        "# )\n",
        "\n",
        "# trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MR2lfgyZ0JV8",
        "outputId": "a7ed3abc-2056-4288-bc8d-291ee69945d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 9600\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1500\n",
            "  Number of trainable parameters = 1538\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-88c42f6daf42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         )\n\u001b[0;32m-> 1543\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cannot pin 'torch.cuda.LongTensor' only dense CPU tensors can be pinned"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n",
        "\n",
        "#trainer.save_model(output_dir='./output_dir')"
      ],
      "metadata": {
        "id": "yyEjTnU3R67u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 测试模型效果"
      ],
      "metadata": {
        "id": "JJPAHGr-LEW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def test(loader_test, model, loss_fn):\n",
        "#   size = len(loader_test.dataset)\n",
        "#   num_batches = len(loader_test)\n",
        "#   model.eval()\n",
        "#   correct = 0\n",
        "#   total = 0\n",
        "#   for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader_test):\n",
        "#     with torch.no_grad():\n",
        "#       out = model(input_ids=input_ids,\n",
        "#                         attention_mask=attention_mask,\n",
        "#                         token_type_ids=token_type_ids)\n",
        "    \n",
        "#     out = out.argmax(dim=1)\n",
        "#     correct += (out == labels).sum().item()\n",
        "#     total += len(labels)\n",
        "#   print(\"Test Accuracy:{accuracy:.3f}\".format(accuracy=correct / total))\n",
        "\n",
        "\n",
        "\n",
        "# test()"
      ],
      "metadata": {
        "id": "H8ZyuCD9K_tN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}